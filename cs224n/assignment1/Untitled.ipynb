{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'yourvectors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0172cad050eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dev\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-0172cad050eb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0mnWords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myourvectors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_saved_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         wordVectors = np.concatenate(\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'yourvectors'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import ipdb\n",
    "\n",
    "from utils.treebank import StanfordSentiment\n",
    "import utils.glove as glove\n",
    "\n",
    "from q3_sgd import load_saved_params, sgd\n",
    "\n",
    "# We will use sklearn here because it will run faster than implementing\n",
    "# ourselves. However, for other parts of this assignment you must implement\n",
    "# the functions yourself!\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def getArguments():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    group = parser.add_mutually_exclusive_group(required=True)\n",
    "    group.add_argument(\"--pretrained\", dest=\"pretrained\", action=\"store_true\",\n",
    "                       help=\"Use pretrained GloVe vectors.\")\n",
    "    group.add_argument(\"--yourvectors\", dest=\"yourvectors\", action=\"store_true\",\n",
    "                       help=\"Use your vectors from q3.\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def getSentenceFeatures(tokens, wordVectors, sentence):\n",
    "    \"\"\"\n",
    "    Obtain the sentence feature for sentiment analysis by averaging its\n",
    "    word vectors\n",
    "    \"\"\"\n",
    "\n",
    "    # Implement computation for the sentence features given a sentence.\n",
    "\n",
    "    # Inputs:\n",
    "    # tokens -- a dictionary that maps words to their indices in\n",
    "    #           the word vector list\n",
    "    # wordVectors -- word vectors (each row) for all tokens\n",
    "    # sentence -- a list of words in the sentence of interest\n",
    "\n",
    "    # Output:\n",
    "    # - sentVector: feature vector for the sentence\n",
    "\n",
    "    sentVector = np.zeros((wordVectors.shape[1],))\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    sentVecotr = np.mean(wordVectors, axis=0)\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    assert sentVector.shape == (wordVectors.shape[1],)\n",
    "    return sentVector\n",
    "\n",
    "\n",
    "def getRegularizationValues():\n",
    "    \"\"\"Try different regularizations\n",
    "\n",
    "    Return a sorted list of values to try.\n",
    "    \"\"\"\n",
    "    values = None   # Assign a list of floats in the block below\n",
    "    ### YOUR CODE HERE\n",
    "    values = [1e-5, 1e-4, 1e-3]\n",
    "    ### END YOUR CODE\n",
    "    return sorted(values)\n",
    "\n",
    "\n",
    "def chooseBestModel(results):\n",
    "    \"\"\"Choose the best model based on dev set performance.\n",
    "\n",
    "    Arguments:\n",
    "    results -- A list of python dictionaries of the following format:\n",
    "        {\n",
    "            \"reg\": regularization,\n",
    "            \"clf\": classifier,\n",
    "            \"train\": trainAccuracy,\n",
    "            \"dev\": devAccuracy,\n",
    "            \"test\": testAccuracy\n",
    "        }\n",
    "\n",
    "    Each dictionary represents the performance of one model.\n",
    "\n",
    "    Returns:\n",
    "    Your chosen result dictionary.\n",
    "    \"\"\"\n",
    "    bestResult = None\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    bestResult = \"reg\"\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return bestResult\n",
    "\n",
    "\n",
    "def accuracy(y, yhat):\n",
    "    \"\"\" Precision for classifier \"\"\"\n",
    "    assert(y.shape == yhat.shape)\n",
    "    return np.sum(y == yhat) * 100.0 / y.size\n",
    "\n",
    "\n",
    "def plotRegVsAccuracy(regValues, results, filename):\n",
    "    \"\"\" Make a plot of regularization vs accuracy \"\"\"\n",
    "    plt.plot(regValues, [x[\"train\"] for x in results])\n",
    "    plt.plot(regValues, [x[\"dev\"] for x in results])\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel(\"regularization\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend(['train', 'dev'], loc='upper left')\n",
    "    plt.savefig(filename)\n",
    "\n",
    "\n",
    "def outputConfusionMatrix(features, labels, clf, filename):\n",
    "    \"\"\" Generate a confusion matrix \"\"\"\n",
    "    pred = clf.predict(features)\n",
    "    cm = confusion_matrix(labels, pred, labels=list(range(5)))\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Reds)\n",
    "    plt.colorbar()\n",
    "    classes = [\"- -\", \"-\", \"neut\", \"+\", \"+ +\"]\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(list(range(cm.shape[0])), list(range(cm.shape[1]))):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(filename)\n",
    "\n",
    "\n",
    "def outputPredictions(dataset, features, labels, clf, filename):\n",
    "    \"\"\" Write the predictions to file \"\"\"\n",
    "    pred = clf.predict(features)\n",
    "    with open(filename, \"w\") as f:\n",
    "        print(\"True\\tPredicted\\tText\", file=f)\n",
    "        for i in range(len(dataset)):\n",
    "            print(\"%d\\t%d\\t%s\" % (\n",
    "                labels[i], pred[i], \" \".join(dataset[i][0])), file=f)\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    \"\"\" Train a model to do sentiment analyis\"\"\"\n",
    "\n",
    "    # Load the dataset\n",
    "\n",
    "    elif args.pretrained:\n",
    "        wordVectors = glove.loadWordVectors(tokens)\n",
    "    dimVectors = wordVectors.shape[1]\n",
    "\n",
    "    # Load the train set\n",
    "    trainset = dataset.getTrainSentences()\n",
    "    nTrain = len(trainset)\n",
    "    trainFeatures = np.zeros((nTrain, dimVectors))\n",
    "    trainLabels = np.zeros((nTrain,), dtype=np.int32)\n",
    "    for i in range(nTrain):\n",
    "        words, trainLabels[i] = trainset[i]\n",
    "        trainFeatures[i, :] = getSentenceFeatures(tokens, wordVectors, words)\n",
    "\n",
    "    # Prepare dev set features\n",
    "    devset = dataset.getDevSentences()\n",
    "    nDev = len(devset)\n",
    "    devFeatures = np.zeros((nDev, dimVectors))\n",
    "    devLabels = np.zeros((nDev,), dtype=np.int32)\n",
    "    for i in range(nDev):\n",
    "        words, devLabels[i] = devset[i]\n",
    "        devFeatures[i, :] = getSentenceFeatures(tokens, wordVectors, words)\n",
    "\n",
    "    # Prepare test set features\n",
    "    testset = dataset.getTestSentences()\n",
    "    nTest = len(testset)\n",
    "    testFeatures = np.zeros((nTest, dimVectors))\n",
    "    testLabels = np.zeros((nTest,), dtype=np.int32)\n",
    "    for i in range(nTest):\n",
    "        words, testLabels[i] = testset[i]\n",
    "        testFeatures[i, :] = getSentenceFeatures(tokens, wordVectors, words)\n",
    "\n",
    "    # We will save our results from each run\n",
    "    results = []\n",
    "    regValues = getRegularizationValues()\n",
    "    for reg in regValues:\n",
    "        print(\"Training for reg=%f\" % reg)\n",
    "        # Note: add a very small number to regularization to please the library\n",
    "        clf = LogisticRegression(C=1.0/(reg + 1e-12))\n",
    "        clf.fit(trainFeatures, trainLabels)\n",
    "\n",
    "        # Test on train set\n",
    "        pred = clf.predict(trainFeatures)\n",
    "        trainAccuracy = accuracy(trainLabels, pred)\n",
    "        print(\"Train accuracy (%%): %f\" % trainAccuracy)\n",
    "\n",
    "        # Test on dev set\n",
    "        pred = clf.predict(devFeatures)\n",
    "        devAccuracy = accuracy(devLabels, pred)\n",
    "        print(\"Dev accuracy (%%): %f\" % devAccuracy)\n",
    "\n",
    "        # Test on test set\n",
    "        # Note: always running on test is poor style. Typically, you should\n",
    "        # do this only after validation.\n",
    "        pred = clf.predict(testFeatures)\n",
    "        testAccuracy = accuracy(testLabels, pred)\n",
    "        print(\"Test accuracy (%%): %f\" % testAccuracy)\n",
    "\n",
    "        results.append({\n",
    "            \"reg\": reg,\n",
    "            \"clf\": clf,\n",
    "            \"train\": trainAccuracy,\n",
    "            \"dev\": devAccuracy,\n",
    "            \"test\": testAccuracy})\n",
    "\n",
    "    # Print the accuracies\n",
    "    print(\"\")\n",
    "    print(\"=== Recap ===\")\n",
    "    print(\"Reg\\t\\tTrain\\tDev\\tTest\")\n",
    "    for result in results:\n",
    "        print(\"%.2E\\t%.3f\\t%.3f\\t%.3f\" % (\n",
    "            result[\"reg\"],\n",
    "            result[\"train\"],\n",
    "            result[\"dev\"],\n",
    "            result[\"test\"]))\n",
    "    print(\"\")\n",
    "\n",
    "    bestResult = chooseBestModel(results)\n",
    "    print(\"Best regularization value: %0.2E\" % bestResult[\"reg\"])\n",
    "    print(\"Test accuracy (%%): %f\" % bestResult[\"test\"])\n",
    "\n",
    "    # do some error analysis\n",
    "    if args.pretrained:\n",
    "        plotRegVsAccuracy(regValues, results, \"q4_reg_v_acc.png\")\n",
    "        outputConfusionMatrix(devFeatures, devLabels, bestResult[\"clf\"],\n",
    "                              \"q4_dev_conf.png\")\n",
    "        outputPredictions(devset, devFeatures, devLabels, bestResult[\"clf\"],\n",
    "                          \"q4_dev_pred.txt\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-67d1e263ad41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_saved_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m wordVectors = np.concatenate(\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mwordVectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnWords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordVectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnWords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         axis=1)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "dataset = StanfordSentiment()\n",
    "tokens = dataset.tokens()\n",
    "nWords = len(tokens)\n",
    "\n",
    "_, wordVectors, _ = load_saved_params()\n",
    "wordVectors = np.concatenate((wordVectors[:nWords,:], wordVectors[nWords:,:]),axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
